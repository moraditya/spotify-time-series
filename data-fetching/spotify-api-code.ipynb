{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa06c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from notebook.services.config import ConfigManager\n",
    "import logging\n",
    "import requests\n",
    "import base64\n",
    "import concurrent.futures\n",
    "from ratelimit import limits, sleep_and_retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the data\n",
    "streams_df = pd.read_csv(r'/Users/adityamxr/Desktop/spotify-time-series/data-fetching/streams_df_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcadb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the IOPub data rate limit to prevent the notebook from stopping output \n",
    "# when processing large volumes of data or handling frequent API rate limiting messages\n",
    "\n",
    "cm = ConfigManager().update('notebook', {'NotebookApp': {'iopub_data_rate_limit': 100000000}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# spotify API credentials\n",
    "client_id = '56b1d34cf1574e28855dc07f73f7754c'\n",
    "client_secret = '490ebd868e76461fbd7dcb7a0a9cce8f'\n",
    "\n",
    "# cache to store artist-genre mappings\n",
    "genre_cache = {}\n",
    "\n",
    "# function to get the access token\n",
    "def get_access_token(client_id, client_secret):\n",
    "    token_url = \"https://accounts.spotify.com/api/token\"\n",
    "    credentials = f\"{client_id}:{client_secret}\"\n",
    "    encoded_credentials = base64.b64encode(credentials.encode()).decode()\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {encoded_credentials}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"grant_type\": \"client_credentials\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(token_url, headers=headers, data=data)\n",
    "    response.raise_for_status()\n",
    "    access_token = response.json().get('access_token')\n",
    "    return access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2cb0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the access token\n",
    "access_token = get_access_token(client_id, client_secret)\n",
    "\n",
    "# rate-limited function to fetch genres for a given artist\n",
    "@sleep_and_retry\n",
    "@limits(calls=10, period=1)\n",
    "def get_artist_genres(artist_name, access_token):\n",
    "    search_url = \"https://api.spotify.com/v1/search\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\"\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": artist_name,\n",
    "        \"type\": \"artist\",\n",
    "        \"limit\": 1\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        artists = data.get('artists', {}).get('items', [])\n",
    "\n",
    "        if not artists:\n",
    "            logging.warning(f\"No artist found for {artist_name}\")\n",
    "            return []\n",
    "\n",
    "        artist_info = artists[0]\n",
    "        genres = artist_info.get('genres', [])\n",
    "        return genres\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error fetching data for {artist_name}: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e358926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that uses caching to fetch genres\n",
    "def get_artist_genres_cached(artist_name, access_token):\n",
    "    if artist_name in genre_cache:\n",
    "        logging.info(f\"Cache hit for '{artist_name}'\")\n",
    "        return genre_cache[artist_name]\n",
    "    \n",
    "    genres = get_artist_genres(artist_name, access_token)\n",
    "    genre_cache[artist_name] = genres  # Store the result in the cache\n",
    "    logging.info(f\"Fetched and cached genres for '{artist_name}': {genres}\")\n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a484a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fetch genres for a list of artists in parallel, using caching and rate limiting\n",
    "def fetch_genres_for_artists_parallel(df, access_token):\n",
    "    # Ensure the 'genres' column exists\n",
    "    df['genres'] = None\n",
    "\n",
    "    def get_genres_for_multiple_artists(artists_list):\n",
    "        all_genres = set()\n",
    "        for artist in artists_list:\n",
    "            if isinstance(artist, str):  # Ensure that artist is a string\n",
    "                genres = get_artist_genres_cached(artist, access_token)\n",
    "                all_genres.update(genres)\n",
    "        return list(all_genres) if all_genres else []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(get_genres_for_multiple_artists, row['artists']): idx for idx, row in df.iterrows()}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            idx = futures[future]\n",
    "            try:\n",
    "                genres = future.result()\n",
    "                df.at[idx, 'genres'] = genres\n",
    "                logging.info(f\"Updated genres for index {idx}: {genres}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing index {idx}: {e}\")\n",
    "                df.at[idx, 'genres'] = []\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure each entry in the 'artists' column is a list\n",
    "streams_df['artists'] = streams_df['artists'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# test with a small subset of the DataFrame\n",
    "test_df_with_genres = fetch_genres_for_artists_parallel(streams_df, access_token)\n",
    "print(test_df_with_genres.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9204a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of rows where the genres column is empty\n",
    "empty_genre_count = streams_df['genres'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "print(f\"Number of rows with empty genres: {empty_genre_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the empty lists in the genre column with \"unknown\"\n",
    "\n",
    "for i in range(len(streams_df)):\n",
    "    if len(streams_df.at[i, 'genres']) == 0:\n",
    "        streams_df.at[i, 'genres'] = [\"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e1e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the empty lists again\n",
    "empty_genre_count = streams_df['genres'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "print(f\"Number of rows with empty genres: {empty_genre_count}\")\n",
    "\n",
    "# empty lists have been imputated with \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d558e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify imputation\n",
    "print(streams_df['genres'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e552dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In depth EDA\n",
    "# check shape of dataframe\n",
    "print(f\"Dataset Shape: {streams_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70235293",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_df.popularity.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee618ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the range of the popularity feature\n",
    "popularity_min = streams_df['popularity'].min()\n",
    "popularity_max = streams_df['popularity'].max()\n",
    "\n",
    "print(f\"The range of popularity values is from {popularity_min} to {popularity_max}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49076a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before proceeding with EDA, let's save the dataframe to a csv since the API genre fetch took nearly 3 hours!\n",
    "streams_df.to_csv('streams_df_with_genres.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d444335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# popularity does not have any missing values. The ID, name, artists, and explicit columns are of no \n",
    "# significance to this analysis, so we'll be dropping them\n",
    "\n",
    "columns_drop = ['id', 'explicit','artists','name']\n",
    "streams_df_clean = streams_df.drop(columns=columns_drop)\n",
    "streams_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ec75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no nulls exist across all features. Compute the data range for the year feature\n",
    "\n",
    "streams_df_clean.year.min(), streams_df_clean.year.max(), streams_df_clean.year.max() - streams_df_clean.year.min()\n",
    "\n",
    "# 99 years of data exists, so the granularity of the time series can be in years. day/month granularity is \n",
    "# unnecessary since our goal is to forecast genre popularity over the next few decades\n",
    "# therefore the release date column can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b619cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_df_clean_2 = streams_df_clean.drop(columns = 'release_date')\n",
    "streams_df_clean_2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
