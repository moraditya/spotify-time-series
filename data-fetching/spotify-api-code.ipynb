{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741baba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from notebook.services.config import ConfigManager\n",
    "import logging\n",
    "import requests\n",
    "import base64\n",
    "import concurrent.futures\n",
    "from ratelimit import limits, sleep_and_retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c24612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the data\n",
    "streams_df = pd.read_csv(r'/Users/adityamxr/Desktop/spotify-time-series/data-fetching/streams_df_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the IOPub data rate limit to prevent the notebook from stopping output \n",
    "# when processing large volumes of data or handling frequent API rate limiting messages\n",
    "\n",
    "cm = ConfigManager().update('notebook', {'NotebookApp': {'iopub_data_rate_limit': 100000000}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# spotify API credentials\n",
    "client_id = '56b1d34cf1574e28855dc07f73f7754c'\n",
    "client_secret = '490ebd868e76461fbd7dcb7a0a9cce8f'\n",
    "\n",
    "# cache to store artist-genre mappings\n",
    "genre_cache = {}\n",
    "\n",
    "# function to get the access token\n",
    "def get_access_token(client_id, client_secret):\n",
    "    token_url = \"https://accounts.spotify.com/api/token\"\n",
    "    credentials = f\"{client_id}:{client_secret}\"\n",
    "    encoded_credentials = base64.b64encode(credentials.encode()).decode()\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {encoded_credentials}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"grant_type\": \"client_credentials\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(token_url, headers=headers, data=data)\n",
    "    response.raise_for_status()\n",
    "    access_token = response.json().get('access_token')\n",
    "    return access_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the access token using the provided client ID and client secret\n",
    "access_token = get_access_token(client_id, client_secret)\n",
    "\n",
    "# define a rate-limited function to fetch genres for a given artist from the spotify api\n",
    "# the function is rate-limited to 10 calls per second using the 'limits' decorator\n",
    "@sleep_and_retry  # retry the request if rate limits are hit\n",
    "@limits(calls=10, period=1)  # limit to 10 API calls per second\n",
    "def get_artist_genres(artist_name, access_token):\n",
    "    # spotify api endpoint to search for an artist\n",
    "    search_url = \"https://api.spotify.com/v1/search\"\n",
    "    \n",
    "    # set up the authorization header with the Bearer token\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\"\n",
    "    }\n",
    "    \n",
    "    # set up the query parameters to search for the artist by name\n",
    "    params = {\n",
    "        \"q\": artist_name,  # artist name to search for\n",
    "        \"type\": \"artist\",  # specify that we are searching for an artist\n",
    "        \"limit\": 1  # limit the search to 1 artist (the most relevant one)\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # make the GET request to the Spotify API to search for the artist\n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "        response.raise_for_status()  # Raise an exception for any HTTP errors\n",
    "        \n",
    "        # parse the JSON response to extract artist data\n",
    "        data = response.json()\n",
    "        artists = data.get('artists', {}).get('items', [])\n",
    "\n",
    "        # if no artist is found, log a warning and return an empty list\n",
    "        if not artists:\n",
    "            logging.warning(f\"No artist found for {artist_name}\")\n",
    "            return []\n",
    "\n",
    "        # get the genres associated with the first (most relevant) artist found\n",
    "        artist_info = artists[0]\n",
    "        genres = artist_info.get('genres', [])\n",
    "        return genres\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # log any exceptions that occur during the API request\n",
    "        logging.error(f\"Error fetching data for {artist_name}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cba67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fetch genres for an artist with caching to avoid redundant API calls\n",
    "def get_artist_genres_cached(artist_name, access_token):\n",
    "    # check if the artist's genres are already in the cache\n",
    "    if artist_name in genre_cache:\n",
    "        logging.info(f\"Cache hit for '{artist_name}'\")\n",
    "        return genre_cache[artist_name]\n",
    "    \n",
    "    # if not in the cache, fetch the genres from the Spotify API\n",
    "    genres = get_artist_genres(artist_name, access_token)\n",
    "    \n",
    "    # store the fetched genres in the cache for future use\n",
    "    genre_cache[artist_name] = genres\n",
    "    logging.info(f\"Fetched and cached genres for '{artist_name}': {genres}\")\n",
    "    \n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fetch genres for a list of artists in parallel, using caching and rate limiting\n",
    "def fetch_genres_for_artists_parallel(df, access_token):\n",
    "    # ensure the 'genres' column exists in the dataframe\n",
    "    df['genres'] = None\n",
    "\n",
    "    def get_genres_for_multiple_artists(artists_list):\n",
    "        all_genres = set()\n",
    "        for artist in artists_list:\n",
    "            if isinstance(artist, str):  # ensure that artist is a string\n",
    "                genres = get_artist_genres_cached(artist, access_token)\n",
    "                all_genres.update(genres)  # add the fetched genres to the set\n",
    "        return list(all_genres) if all_genres else []\n",
    "\n",
    "    # create a thread pool to process artists in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # map the future tasks to their respective dataframe indices\n",
    "        futures = {executor.submit(get_genres_for_multiple_artists, row['artists']): idx for idx, row in df.iterrows()}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            idx = futures[future]  # get the index of the dataframe row\n",
    "            try:\n",
    "                genres = future.result()  # get the result of the future task\n",
    "                df.at[idx, 'genres'] = genres  # update the dataframe with the fetched genres\n",
    "                logging.info(f\"Updated genres for index {idx}: {genres}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing index {idx}: {e}\")\n",
    "                df.at[idx, 'genres'] = []  # set genres to an empty list if an error occurs\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure each entry in the 'artists' column is a list\n",
    "streams_df['artists'] = streams_df['artists'].apply(lambda x: x if isinstance(x, list) else [x])\n",
    "\n",
    "# test with a small subset of the DataFrame\n",
    "test_df_with_genres = fetch_genres_for_artists_parallel(streams_df, access_token)\n",
    "print(test_df_with_genres.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521355a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of rows where the genres column is empty\n",
    "empty_genre_count = streams_df['genres'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "print(f\"Number of rows with empty genres: {empty_genre_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc353c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the empty lists in the genre column with \"unknown\"\n",
    "\n",
    "for i in range(len(streams_df)):\n",
    "    if len(streams_df.at[i, 'genres']) == 0:\n",
    "        streams_df.at[i, 'genres'] = [\"Unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the empty lists again\n",
    "empty_genre_count = streams_df['genres'].apply(lambda x: len(x) == 0).sum()\n",
    "\n",
    "print(f\"Number of rows with empty genres: {empty_genre_count}\")\n",
    "\n",
    "# empty lists have been imputated with \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b856ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify imputation\n",
    "print(streams_df['genres'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7397c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic EDA\n",
    "# check shape of dataframe\n",
    "print(f\"Dataset Shape: {streams_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f489aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_df.popularity.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ed927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the range of the popularity feature\n",
    "popularity_min = streams_df['popularity'].min()\n",
    "popularity_max = streams_df['popularity'].max()\n",
    "\n",
    "print(f\"The range of popularity values is from {popularity_min} to {popularity_max}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before proceeding with EDA, let's save the dataframe to a csv since the API genre fetch took nearly 3 hours!\n",
    "streams_df.to_csv('streams_df_with_genres.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda7016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# popularity does not have any missing values. The ID, name, artists, and explicit columns are of no \n",
    "# significance to this analysis, so we'll be dropping them\n",
    "\n",
    "columns_drop = ['id', 'explicit','artists','name']\n",
    "streams_df_clean = streams_df.drop(columns=columns_drop)\n",
    "streams_df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a85784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no nulls exist across all features. Compute the data range for the year feature\n",
    "\n",
    "streams_df_clean.year.min(), streams_df_clean.year.max(), streams_df_clean.year.max() - streams_df_clean.year.min()\n",
    "\n",
    "# 99 years of data exists, so the granularity of the time series can be in years. day/month granularity is \n",
    "# unnecessary since our goal is to forecast genre popularity over the next few decades\n",
    "# therefore the release date column can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_df_clean_2 = streams_df_clean.drop(columns = 'release_date')\n",
    "streams_df_clean_2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
